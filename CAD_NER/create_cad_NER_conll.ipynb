{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from nltk.tokenize.punkt import PunktSentenceTokenizer as pst\n",
    "from transformers import BertTokenizerFast, BatchEncoding\n",
    "# PST = pst()\n",
    "import warnings\n",
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brat_parser import get_entities_relations_attributes_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_annotations():\n",
    "    train_complete_annotations_paths = ['../../n2c2/training-RiskFactors-Complete-Set1/','../../n2c2/training-RiskFactors-Complete-Set2/']\n",
    "    train_complete_annotations_paths = ['../../n2c2/complete/', '../../n2c2/testing-RiskFactors-Complete']\n",
    "\n",
    "    rows = []\n",
    "    childnum = 0\n",
    "    gold_rows = []\n",
    "    for train_complete_annotations_path in train_complete_annotations_paths:\n",
    "        for fn in os.listdir(train_complete_annotations_path):\n",
    "            tree = ET.parse(train_complete_annotations_path+'/'+fn)\n",
    "            root = tree.getroot()\n",
    "            (TEXT,TAGS) = [child for child in root]\n",
    "            notetext = TEXT.text\n",
    "            for child in TAGS:\n",
    "#                 print(child.tag)\n",
    "                gold_row = child.attrib\n",
    "                gold_row['filename'] = fn\n",
    "                gold_row['note_text'] = notetext\n",
    "                gold_row['tag'] = child.tag\n",
    "                gold_row['observation_number'] = childnum\n",
    "                gold_row['evidence_spans'] = []\n",
    "                gold_row['text_cues'] = []\n",
    "                row = child.attrib\n",
    "                if 'start' in row.keys():\n",
    "                    gold_row['evidence_spans'].append((int(row['start']),int(row['end'])))\n",
    "                    gold_row['text_cues'].append(row['text'])\n",
    "                for grandchild in child:\n",
    "                    row = grandchild.attrib\n",
    "                    row['filename'] = fn\n",
    "                    row['note_text'] = notetext\n",
    "\n",
    "#                     row['text'] = notetext\n",
    "                    row['tag'] = child.tag\n",
    "                    row['observation_number'] = childnum\n",
    "                    rows.append(row)\n",
    "                    if 'start' in row.keys():\n",
    "                        gold_row['evidence_spans'].append((int(row['start']),int(row['end'])))\n",
    "                        gold_row['text_cues'].append(row['text'])\n",
    "                gold_rows.append(gold_row)\n",
    "                childnum+=1\n",
    "    return pd.DataFrame(rows), pd.DataFrame(gold_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_annotations():\n",
    "    train_gold_annotations_paths = ['../../n2c2/training-RiskFactors-Gold-Set1/','../../n2c2/training-RiskFactors-Gold-Set2/']\n",
    "    rows = []\n",
    "    for train_gold_annotations_path in train_gold_annotations_paths:\n",
    "        for fn in os.listdir(train_gold_annotations_path):\n",
    "            tree = ET.parse(train_gold_annotations_path+'/'+fn)\n",
    "            root = tree.getroot()\n",
    "            (TEXT,TAGS) = [child for child in root]\n",
    "            notetext = TEXT.text\n",
    "            for child in TAGS:\n",
    "    #             print(child.tag, child.attrib)\n",
    "                row = child.attrib\n",
    "                row['filename'] = fn\n",
    "                row['text'] = notetext\n",
    "                row['tag'] = child.tag\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dina_annotations():\n",
    "    annotations = pd.DataFrame()\n",
    "\n",
    "    bad=0\n",
    "    for dina_annotations_path in ['../../n2c2/evens/' , '../../n2c2/odds/' ]:\n",
    "        for dir in [dina_annotations_path+dir+'/' for dir in os.listdir(dina_annotations_path)]:\n",
    "#             print(dir)\n",
    "            RF = dir.split('/')[-1]\n",
    "            if os.path.isdir(dir):\n",
    "#                 print(dir)\n",
    "                fns = [dir+ x for x in os.listdir(dir)]# +[dir+'/even/'+ x for x in os.listdir(dir+'/even/')]\n",
    "#                 random.shuffle(fns)\n",
    "                for fn in fns:\n",
    "                    if '.txt' in fn:\n",
    "                        with open(fn, 'r') as notefile:\n",
    "                            notetext = notefile.read()\n",
    "                        fn_base = fn.split('.txt')[0]\n",
    "                        ann_fn = fn_base +'.ann'\n",
    "                        ann_df =  pd.read_csv(ann_fn, sep='\\t', names=['TA','TYPE','TEXT'])\n",
    "                        entities, relations, attributes, groups = get_entities_relations_attributes_groups(ann_fn)\n",
    "                        if not relations=={}:\n",
    "                            return relations\n",
    "                        attr_df =  pd.DataFrame([([getattr(v, x) for x in vars(v)]) for _,v in attributes.items() ], columns=['id', 'type','target', 'values'])\n",
    "                        entities_df =  pd.DataFrame([([getattr(v, x) for x in vars(v)]) for _,v in entities.items() ], columns=['id', 'type','span', 'text'])\n",
    "                        entities_df['note_text']= [notetext]*len(entities_df)\n",
    "                        entities_df['filename']=fn.split('/')[-1]\n",
    "                        entities_df['RF'] = dir.split('/')[-2]\n",
    "                        if not attr_df.empty:\n",
    "                            entities_df['values'] = entities_df['id'].map(attr_df.groupby('target').apply(lambda x: list(x['values'])))\n",
    "                            entities_df['types'] = entities_df['id'].map(attr_df.groupby('target').apply(lambda x: list(x['type'])))\n",
    "                        annotations = pd.concat([annotations,entities_df])\n",
    "                        \n",
    "    return annotations\n",
    "                        #                     return attr_df\n",
    "    #                     return entities_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dina_annotations = get_dina_annotations()\n",
    "# get_dina_annotations()\n",
    "# os.listdir('../../n2c2/dina/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df, gold_df = get_complete_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'time', 'type1', 'type2', 'filename', 'note_text', 'tag',\n",
       "       'observation_number', 'evidence_spans', 'text_cues', 'status',\n",
       "       'indicator', 'start', 'end', 'text', 'TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df[gold_df['indicator'].apply(lambda x: 'bp' in str(x).lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CADMention', 'HyperlipidemiaMention', 'SmokerMention', 'CADEvent',\n",
       "       'ObeseMention', 'DiabetesMention', 'LDL', 'CADTestResult',\n",
       "       'Cholesterol', 'BMI', 'Medication2', 'Glucose', 'A1C',\n",
       "       'BloodPressure', 'CADSymptom', 'HypertensionMention',\n",
       "       'Medication1'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(unravel(dina_annotations[dina_annotations['type'].apply(lambda x: 'Smoker' in x)]['types'].dropna())).unique()\n",
    "dina_annotations['RF'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoker_override = {\"221-04\":\"current\",\"241-01\": \"unknown\",\"242-02\":\"past\",\"246-02\":\"current\", \"246-03\": \"unknown\",\"277-03\":\"never\",\"279-01\":\"ever\",\n",
    "                            \"279-02\":\"current\",\"291-05\":\"past\", \"295-01\": \"ever\",\"296-03\":\"past\",\"298-05\":\"unknown\",\"303-04\":\"ever\",\n",
    "                                                    \"320-01\": \"unknown\",\"320-02\":\"unknown\",\"320-03\": \"unknown\",\"321-03\":\"never\",\"322-01\": \"never\",\"399-01\": \"current\",\"399-02\":\"never\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdict = {'CADMention':'CAD', 'HyperlipidemiaMention':'HYPERLIPIDEMIA', 'SmokerMention':'SMOKER', 'CADEvent':'CAD',\n",
    "       'ObeseMention':'OBESE', 'DiabetesMention':'DIABETES', 'LDL':'HYPERLIPIDEMIA', 'CADTestResult':'CAD',\n",
    "       'Cholesterol':'HYPERLIPIDEMIA', 'BMI':'OBESE', 'Medication2':'MEDICATION', 'Glucose':'DIABETES', 'A1C':'DIABETES',\n",
    "       'BloodPressure':'HYPERTENSION', 'CADSymptom':'CAD', 'HypertensionMention':'HYPERTENSION', 'Medication1':'MEDICATION'}\n",
    "\n",
    "def transform_brat_df_row(row):\n",
    "    \n",
    "    if type(row['types'])==float:\n",
    "        row['types']=[]\n",
    "    if 'Invalid' in row['types'] or 'Negation' in row['types']:\n",
    "        return np.nan\n",
    "    rowdict = {x:np.nan for x in ['id', 'time', 'type1', 'type2', 'filename', 'note_text', 'tag','observation_number', 'evidence_spans', 'text_cues', 'status', 'indicator', 'start', 'end', 'text', 'TYPE']}\n",
    "    rowdict['tag'] = tagdict[row['RF']]\n",
    "    rowdict['filename'] = row['filename'].replace('txt','xml')\n",
    "    rowdict['note_text']=row['note_text']\n",
    "    if 'Time_During'in row['types']:\n",
    "        rowdict['time']='during DCT'\n",
    "    elif 'Time_After'in row['types']:\n",
    "        rowdict['time'] = 'after DCT'\n",
    "    elif 'Time_Before' in row['types']:\n",
    "        rowdict['time']= 'before DCT'\n",
    "    else:\n",
    "        rowdict['time']=np.nan\n",
    "    if 'Medication' in row['RF']:\n",
    "        if row['type'].startswith('Gold_') :\n",
    "            drugs=row['type'][5:].replace('_',' ').split('+')\n",
    "        elif row['type'].startswith('Gold') :\n",
    "            drugs=row['type'][4:].replace('_',' ').split('+')\n",
    "        else:\n",
    "            drugs =row['type'].replace('_',' ').split('+')\n",
    "        rowdict['type1']=drugs[0]\n",
    "        if len(drugs)==2:\n",
    "            rowdict['type2'] =drugs[1]\n",
    "        rowdict['tag']='MEDICATION'\n",
    "    elif 'Smoker' in row['RF']:\n",
    "        rowdict['tag']='SMOKER'\n",
    "        rowdict['status'] = 'brat' \n",
    "        if row['filename'].split('.')[0] in smoker_override.keys():\n",
    "            rowdict['status'] = smoker_override[row['filename'].split('.')[0]]\n",
    "            print('smoker override'+row['filename'])\n",
    "    rowdict['evidence_spans'] = list(row['span'])\n",
    "    rowdict['text_cues'] = [row['text']]\n",
    "    return rowdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': nan,\n",
       " 'time': 'during DCT',\n",
       " 'type1': nan,\n",
       " 'type2': nan,\n",
       " 'filename': '244-01.xml',\n",
       " 'note_text': '\\n\\n\\nRecord date: 2089-01-27\\n\\nPotomac Valley Hospital\\n\\nPreadmission Testing Area\\n\\nHistory & Physical Examination\\n\\nand Anesthesia Assessment\\n\\nYvonne Easton, N.P.\\n\\nJenna Corona, N.P.\\n\\nXochitl Narvaez, N.P.\\n\\n\\n\\nFrederick Q. Valladares, M.D.\\n\\nMedical Director\\n\\nJanuary 27, 2089\\n\\n\\n\\nMedical Record Number:  8751045  Francisco, Xue\\n\\n\\n\\nProcedure:  The patient is a 56-year-old Spanish-speaking female scheduled for laparoscopic cholecystectomy.  Surgery is scheduled on January 28, 2089 by Dr. Xavier Israel kenneth Xenos.\\n\\n\\n\\nChief Complaint & Present Illness:  Patient briefly evaluated on 12/30/88 as part of preoperative evaluation for a laparoscopic cholecystectomy then scheduled for 12/31/88.  Over the past year patient has had difficulty with right upper quadrant pain as well as epigastric pain.  These episodes tend to happen more frequently after she has had a rich meal.  Other symptoms that occurred include nausea and vomiting.  Patient denies jaundice.  Today, patient states that she still has some abdominal tenderness greatest at the right costal margin and radiating into right flank.\\n\\n\\n\\nAt the time of evaluation on 12/30/88 patients had symptoms of URI and LRI.  She reported back/green sputum, mild shortness of breath and increased use of her grandson\\'s inhaler.  After consultation with Dr. Valladares it was decided that patient should be evaluated by her primary care provider for further treatment of her respiratory tract infection and then follow-up with surgeon to reschedule her surgery.  Patient reports that she went to University Hospital and there they treated her with antibiotics and inhaler.  Unfortunately patient is unable to recall the name of the antibiotic or the inhaler.  Currently she denies any symptoms of sputum production, cough, shortness of breath, or wheezing.  Also denies fever, chills, nausea, vomiting, and diarrhea.\\n\\n\\n\\nPatient does have a history of coronary artery disease.  She is status post an MI 11/82.  Patient had cardiac catheterization at OSH 12/3/82 that reportedly showed a critical mid right lesion and a mild left main and left anterior descending lesion.  12/09/82 patient underwent cardiac catheterization at PVH and a PTCA was done.  Patient did well until 10/83 when she was admitted to PVH with symptoms of chest tenderness, left arm pain, tachycardia, palpitations, diaphoresis, dry mouth, shortness of breath, dizziness, and darkening of revision.  Patient did rule out for MI by serial enzymes and there are no changes seen on her ECG.  Patient denies any difficulty with chest pain or left arm pain since that time.  She has had episodes of shortness of breath with exertion however, these seem more related to her respiratory status rather than her cardiac disease.\\n\\n\\n\\nStress test done 1/26 showed a normal exercise capacity (METS=7), ECG nondiagnostic for ischemia and the perfusion images were suggestive of anterior ischemia although body habitus limited the interpretation.\\n\\n\\n\\n\\n\\n\\n\\nPast Medical History:  Significant medical problems include:  \\n\\n1.  Hypertension\\n\\n2.  CAD, status post MI 2082, status post PTCA 2082\\n\\n3.  Asthma (no hospitalizations or intubations)\\n\\n4.  Arthritis\\n\\n5.  Systemic Lupus Erythematosus (with clinical manifestations of arthralgia, TTP and a high urine titer)\\n\\n6.  Chronic low back pain, history of herniated discs\\n\\n7.  Depression\\n\\n\\n\\nPast Surgical History:  Prior surgery includes:\\n\\n1.  Status post cardiac catheterization and PTCA, 9/82  \\n\\n2.  Status post D&C secondary to prolonged menstrual bleeding\\n\\n3.  Status post tubal ligation\\n\\n4.  Status post T&A\\n\\n\\n\\nFamily History:  There is no family history of adverse reactions to general anesthesia.\\n\\nBrother: alive, CAD\\n\\nBrother: alive, kidney disease\\n\\n2 brothers: both alive, diabetes\\n\\nSister: deceased age 38, breast CA\\n\\n\\n\\nMedications:  \\n\\npaxil 20 mg q.d.\\n\\natenolol 25 mg q.d.\\n\\nprednisone 10 mg q.d.\\n\\nhydroxychloroquine q.d.\\n\\nnifedipine XR 60 mg q.d.\\n\\nisosorbide 10 mg t.i.d.\\n\\nasthma inhaler (patient unable to recall name)\\n\\naspirin\\n\\n\\n\\nAllergies:  NKA\\n\\ndenies food and environmental allergies\\n\\n\\n\\nSocial History:\\n\\n\\n\\nSmoking:  denies\\n\\nAlcohol use:  denies\\n\\nSubstance Abuse:  denies\\n\\nAllergen Exposure (blood products/pregnancy): none in last 3 months\\n\\nExercise:  going up and down stairs usually, shortness of breath, expanses released when she rests at the top of the stair and drinks water; able to do light housework\\n\\nOccupation:  Firefighter\\n\\nMarital Status:  divorced, four children\\n\\n\\n\\nReview of Systems:  \\n\\n\\n\\nGeneral:  negative\\t\\n\\nHEENT: currently, LRI symptoms have resolved and patient feels much better\\n\\nCardiovascular: see HPI\\n\\nRespiratory: patient reports a diagnosis of asthma however her primary care provider (Dr. Younker X1-1335) who has seen patient for two years does not recall patient having any diagnosis of asthma\\n\\nNeurological: 9/81 patient admitted to PVH with thrombocytopenia purpura.  Suffered a cerebral thrombus with infarction.  Symptoms at the time of admission were severe headache, facial numbness, and facial droop as well as mutism.  Patients underwent plasma phosphor uses and became acutely hypoxic and hypotensive requiring emergent intubation.  Was felt that patient\\'s symptoms or secondary to a transfusion reaction.  No residual symptoms.\\n\\nGastrointestinal: negative\\n\\nHepatobiliary: negative\\n\\nRenal/Genitourinary: negative\\n\\nMusculoskeletal: arthritis affecting hands, and hips, knees, ankles, and elbows\\n\\nPeripheral Vascular: negative\\n\\nEndocrine/metabolic: history of SLE\\n\\nHeme/Onc: negative\\n\\nPsychiatric: negative\\n\\nSkin: negative\\n\\n\\n\\nVital Signs:\\n\\n\\n\\n\\tBP:  149/75 mm Hg\\n\\n\\tP:  61 bpm\\n\\n\\tSaO2:  98%\\n\\n\\tTemp:  98.2 degrees F\\n\\n\\tResp:  16 rpm\\n\\n\\tHt:  64 inches\\n\\n\\tWt:  196.6 pounds\\n\\n\\n\\nExam:\\n\\n\\n\\nGeneral:  well developed, well nourished female\\n\\nHEEN&T:  buffalo hump, fair range of motion, no masses, neck veins flat, no bruits\\n\\nAirway:  Mallampatti Class I\\n\\nTeeth:  in good repair\\n\\nLungs:  clear to auscultation\\n\\nHeart:  regular rhythm, no murmurs, S1=S2, no gallop\\n\\nAbdomen:  diffuse abdominal tenderness with increased tenderness to palpation at costal margin right upper quadrant and radiating into flank, soft, not distended, normal bowel sounds, no organomegaly or palpable masses\\n\\nGU/Rectal:  no CVA tenderness\\n\\nLymphatics:  no lymphadenopathy\\n\\nPeripheral Vascular:\\n\\n\\tcarotids:  2+ bilateral no bruits\\n\\n\\tradials:  2+ bilateral\\n\\nNeurological:\\n\\n\\tcranial nerves: II-XII grossly intact\\n\\nExtremities:  no edema, lower extremities\\n\\nSkin:  no ulcers or rashes observed\\n\\n\\n\\nAssessment:  \\n\\nASA Physical Status II\\n\\n56-year-old female with a history of CAD, SLE, hypertension, arthritis, asthma and chronic low back pain presents for laparoscopic cholecystectomy.  Patient originally scheduled for surgery on 12/31/88 however because of LRI surgery was postponed.  Patient much improved, lungs clear, no wheezing, no shortness of breath.  It has only been three-week since her infection and therefore increased airway reactivity may be an issue.  Dr. Hoffman explained this to patient.  Dr. Hoffman also reviewed with patient medications to take prior to surgery 1/28/89.  Currently, patient denies any symptoms of cardiac ischemia.  Does have chronic chest pain/tenderness which is reproducible by palpation.  Patient states that this is not her \"cardiac pain\".\\n\\n\\n\\nPlan:\\n\\n\\n\\n\\tProposed Anesthetic: general\\n\\n\\tMonitors:  standard\\n\\n\\tPain Management:  oral\\n\\n\\tAutologous blood:  none\\n\\n\\tPremedication:  stress steroid dosing\\n\\n\\tUsual Medications:  paxil, atenolol, prednisone, hydroxychloroquine, nifedipine, Naprosyn, isosorbide, asthma inhaler, aspirin\\n\\n\\tMedications to be held on day of surgery:  hydroxychloroquine, Naprosyn, aspirin\\n\\n\\tDiabetic medications:  not applicable\\n\\n\\tNSAIDS:  will stop as of 1/27/89\\n\\n\\tAspirin:  will stop as of 1/27/89\\n\\n\\tNPO: after midnight the evening before surgery\\n\\n\\n\\nAncillary Studies:  \\n\\nPending\\n\\n\\n\\n\\n\\n\\n\\n_______________________________________________\\n\\nJenna Q. Corona, MSN, RN, CS\\n\\n\\n\\n\\n\\nPATA Medical Director Note:  \\n\\n\\n\\nI have reviewed this preanesthetic assessment and concur with the assessment and recommended plan with the following exceptions:  \\n\\n\\n\\n\\n\\n\\n\\nsigned:  ____________________________________________________________\\n\\n\\n\\nAttending Surgeon Reassessment Note:\\n\\n\\n\\nI have reviewed the above history and physical exam and agree with the findings.  Additional comments: \\n\\n\\n\\n\\n\\n\\n\\nsigned:  ___________________________________________________________ \\n\\n\\n\\n',\n",
       " 'tag': 'CAD',\n",
       " 'observation_number': nan,\n",
       " 'evidence_spans': [(3041, 3044)],\n",
       " 'text_cues': ['CAD'],\n",
       " 'status': nan,\n",
       " 'indicator': nan,\n",
       " 'start': nan,\n",
       " 'end': nan,\n",
       " 'text': nan,\n",
       " 'TYPE': nan}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_brat_df_row(dina_annotations.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoker override296-03.txt\n",
      "smoker override242-02.txt\n",
      "smoker override322-01.txt\n",
      "smoker override246-02.txt\n",
      "smoker override221-04.txt\n",
      "smoker override291-05.txt\n",
      "smoker override295-01.txt\n",
      "smoker override277-03.txt\n",
      "smoker override279-01.txt\n",
      "smoker override303-04.txt\n",
      "smoker override303-04.txt\n",
      "smoker override399-01.txt\n",
      "smoker override399-01.txt\n",
      "smoker override279-02.txt\n",
      "smoker override279-02.txt\n",
      "smoker override241-01.txt\n",
      "smoker override321-03.txt\n",
      "smoker override321-03.txt\n"
     ]
    }
   ],
   "source": [
    "dina_rows = dina_annotations.apply(transform_brat_df_row,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dina_df = pd.DataFrame(list(dina_rows.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(gold_df['tag'].unique())-set(dina_df['tag'].unique())\n",
    "set(dina_df['note_text'].unique())-set(gold_df['note_text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df=pd.concat([gold_df, dina_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MEDICATION', 'SMOKER', 'FAMILY_HIST', 'PHI', 'HYPERTENSION',\n",
       "       'DIABETES', 'HYPERLIPIDEMIA', 'CAD', 'OBESE'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    if 'before' in str(row['time']):\n",
    "        label='before'\n",
    "    else:\n",
    "        if row['tag']=='MEDICATION':\n",
    "            label =  row['tag']#+row['type1']#+row['time'] \n",
    "\n",
    "        elif row['tag']== 'SMOKER':\n",
    "            if row['status']=='never' or row['status']=='unknown':\n",
    "                label='before'\n",
    "            else:\n",
    "                label = 'SMOKER'\n",
    "        elif row['tag'] =='FAMILY_HIST':\n",
    "            label =  row['tag']\n",
    "        elif row['tag'] =='PHI':\n",
    "            label =  'before'#row['tag']#+row['TYPE']\n",
    "        elif row['tag']== 'HYPERTENSION':\n",
    "            label= row['tag']#+row['time']\n",
    "        elif row['tag']=='DIABETES':\n",
    "            label= row['tag']\n",
    "        elif row['tag']=='HYPERLIPIDEMIA':\n",
    "            label= row['tag']\n",
    "        elif row['tag']=='CAD':\n",
    "            label= row['tag']\n",
    "        elif row['tag']== 'OBESE':\n",
    "            label= row['tag']\n",
    "\n",
    "    return [label]*len(row['evidence_spans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df['encoded'] = gold_df['note_text'].map( gold_df.groupby(['note_text']).apply(lambda x: tokenizer.encode_plus(x.name, truncation=True, padding=True) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['labels'] = gold_df.apply(lambda row:get_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "      <th>filename</th>\n",
       "      <th>note_text</th>\n",
       "      <th>tag</th>\n",
       "      <th>observation_number</th>\n",
       "      <th>evidence_spans</th>\n",
       "      <th>text_cues</th>\n",
       "      <th>status</th>\n",
       "      <th>indicator</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOC0</td>\n",
       "      <td>during DCT</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td></td>\n",
       "      <td>303-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(863, 870), (863, 870), (863, 870)]</td>\n",
       "      <td>[Zestril, Zestril, Zestril]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOC1</td>\n",
       "      <td>during DCT</td>\n",
       "      <td>thienopyridine</td>\n",
       "      <td></td>\n",
       "      <td>303-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(1424, 1430), (1424, 1430)]</td>\n",
       "      <td>[Plavix, Plavix]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION, MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOC2</td>\n",
       "      <td>before DCT</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td></td>\n",
       "      <td>303-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(863, 870), (863, 870), (863, 870)]</td>\n",
       "      <td>[Zestril, Zestril, Zestril]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[before, before, before]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOC3</td>\n",
       "      <td>before DCT</td>\n",
       "      <td>beta blocker</td>\n",
       "      <td></td>\n",
       "      <td>303-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(908, 916), (908, 916), (908, 916)]</td>\n",
       "      <td>[Atenolol, Atenolol, Atenolol]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[before, before, before]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOC4</td>\n",
       "      <td>after DCT</td>\n",
       "      <td>ACE inhibitor</td>\n",
       "      <td></td>\n",
       "      <td>303-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[(863, 870), (863, 870), (863, 870)]</td>\n",
       "      <td>[Zestril, Zestril, Zestril]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7700</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calcium channel blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(3059, 3069)]</td>\n",
       "      <td>[amlodipine]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>NaN</td>\n",
       "      <td>during DCT</td>\n",
       "      <td>aspirin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(7273, 7276)]</td>\n",
       "      <td>[ASA]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>during DCT</td>\n",
       "      <td>beta blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257-02.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(7302, 7311)]</td>\n",
       "      <td>[Lopressor]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>NaN</td>\n",
       "      <td>during DCT</td>\n",
       "      <td>aspirin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321-01.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2068-01-04\\n\\n             ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(2261, 2264)]</td>\n",
       "      <td>[ASA]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspirin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321-01.xml</td>\n",
       "      <td>\\n\\n\\nRecord date: 2068-01-04\\n\\n             ...</td>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(2266, 2286)]</td>\n",
       "      <td>[ACETYLSALICYLIC ACID]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MEDICATION]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47215 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        time                    type1 type2    filename  \\\n",
       "0     DOC0  during DCT            ACE inhibitor        303-02.xml   \n",
       "1     DOC1  during DCT           thienopyridine        303-02.xml   \n",
       "2     DOC2  before DCT            ACE inhibitor        303-02.xml   \n",
       "3     DOC3  before DCT             beta blocker        303-02.xml   \n",
       "4     DOC4   after DCT            ACE inhibitor        303-02.xml   \n",
       "...    ...         ...                      ...   ...         ...   \n",
       "7700   NaN         NaN  calcium channel blocker   NaN  257-02.xml   \n",
       "7701   NaN  during DCT                  aspirin   NaN  257-02.xml   \n",
       "7702   NaN  during DCT             beta blocker   NaN  257-02.xml   \n",
       "7703   NaN  during DCT                  aspirin   NaN  321-01.xml   \n",
       "7704   NaN         NaN                  aspirin   NaN  321-01.xml   \n",
       "\n",
       "                                              note_text         tag  \\\n",
       "0     \\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...  MEDICATION   \n",
       "1     \\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...  MEDICATION   \n",
       "2     \\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...  MEDICATION   \n",
       "3     \\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...  MEDICATION   \n",
       "4     \\n\\n\\nRecord date: 2113-03-08\\n\\n \\nMarch 08, ...  MEDICATION   \n",
       "...                                                 ...         ...   \n",
       "7700  \\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...  MEDICATION   \n",
       "7701  \\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...  MEDICATION   \n",
       "7702  \\n\\n\\nRecord date: 2097-03-31\\n\\n\\n\\tCARDIAC S...  MEDICATION   \n",
       "7703  \\n\\n\\nRecord date: 2068-01-04\\n\\n             ...  MEDICATION   \n",
       "7704  \\n\\n\\nRecord date: 2068-01-04\\n\\n             ...  MEDICATION   \n",
       "\n",
       "      observation_number                        evidence_spans  \\\n",
       "0                    0.0  [(863, 870), (863, 870), (863, 870)]   \n",
       "1                    1.0          [(1424, 1430), (1424, 1430)]   \n",
       "2                    2.0  [(863, 870), (863, 870), (863, 870)]   \n",
       "3                    3.0  [(908, 916), (908, 916), (908, 916)]   \n",
       "4                    4.0  [(863, 870), (863, 870), (863, 870)]   \n",
       "...                  ...                                   ...   \n",
       "7700                 NaN                        [(3059, 3069)]   \n",
       "7701                 NaN                        [(7273, 7276)]   \n",
       "7702                 NaN                        [(7302, 7311)]   \n",
       "7703                 NaN                        [(2261, 2264)]   \n",
       "7704                 NaN                        [(2266, 2286)]   \n",
       "\n",
       "                           text_cues status indicator start  end text TYPE  \\\n",
       "0        [Zestril, Zestril, Zestril]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "1                   [Plavix, Plavix]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "2        [Zestril, Zestril, Zestril]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "3     [Atenolol, Atenolol, Atenolol]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "4        [Zestril, Zestril, Zestril]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "...                              ...    ...       ...   ...  ...  ...  ...   \n",
       "7700                    [amlodipine]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "7701                           [ASA]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "7702                     [Lopressor]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "7703                           [ASA]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "7704          [ACETYLSALICYLIC ACID]    NaN       NaN   NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                    labels  \n",
       "0     [MEDICATION, MEDICATION, MEDICATION]  \n",
       "1                 [MEDICATION, MEDICATION]  \n",
       "2                 [before, before, before]  \n",
       "3                 [before, before, before]  \n",
       "4     [MEDICATION, MEDICATION, MEDICATION]  \n",
       "...                                    ...  \n",
       "7700                          [MEDICATION]  \n",
       "7701                          [MEDICATION]  \n",
       "7702                          [MEDICATION]  \n",
       "7703                          [MEDICATION]  \n",
       "7704                          [MEDICATION]  \n",
       "\n",
       "[47215 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df#[gold_df['tag']=='SMOKER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df['encoded'].iloc[0].char_to_token(870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df[gold_df.apply(lambda row: row['tag']=='OBESE',axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df[gold_df['tag']=='SMOKER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df[['note_text','encoded_evidence_indices', 'labels']]#.groupby(['note_text']).apply(lambda x: list(x['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel(lst):\n",
    "    return [i for j in lst for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_indices(row):\n",
    "    ret = []\n",
    "    for span in row['evidence_spans']:\n",
    "        ret.append( [row['encoded'].char_to_token(i) for i in range(span[0],span[1])] )\n",
    "    return ret\n",
    "def get_all_labels(row):\n",
    "    ret = ['O']*len(row['encoded']['input_ids'])\n",
    "    for i,span in enumerate(row['evidence_spans']):\n",
    "        ids =  [row['encoded'].char_to_token(j) for j in range(span[0],span[1])] \n",
    "\n",
    "        for id in ids:\n",
    "            if id is not None:\n",
    "                if row['labels'][i] is not 'before':\n",
    "                    ret[id]='I-'+row['labels'][i]\n",
    "#         for id in ids:\n",
    "#             if id is not None:\n",
    "#                 ret[id]='B-'+row['labels'][i]\n",
    "#                 break\n",
    "    if ret[0]!='O':\n",
    "        ret[0] = 'B'+ret[0][1:]\n",
    "    if ret[-1]!='O' and ret[-2]!=ret[-1]:\n",
    "        ret[-1] = 'B'+ret[-1][1:]\n",
    "    for i in range(1,len(ret)-1):\n",
    "        if ret[i-1][1:]!=ret[i][1:] and ret[i]!='O':\n",
    "            ret[i] = 'B'+ret[i][1:]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped =gold_df.groupby('note_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped['note_text'].apply(lambda x: x.iloc[0])\n",
    "notes_df= grouped.agg({'evidence_spans':unravel, 'labels':unravel,'filename':lambda x: x.iloc[0] }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes_df#[notes_df['note_text'].apply(lambda x: 'LAUREN' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes_df.columns=['note_text', 'labels','evidence_spans']\n",
    "notes_df['encoded'] = notes_df['note_text'].apply(lambda x: tokenizer.encode_plus(x, truncation=False, is_split_into_words=False, padding='max_length', max_length=512) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181.1633435582821"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df['encoded'].apply(lambda x: len(x['input_ids'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gold_df.groupby('note_text')['note_text'].apply(lambda x:x).iloc[0]\n",
    "# notes_df[notes_df['note_text'].apply(lambda x: 'Fern' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['token_labels'] = notes_df.apply(lambda row: get_all_labels(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_text</th>\n",
       "      <th>evidence_spans</th>\n",
       "      <th>labels</th>\n",
       "      <th>filename</th>\n",
       "      <th>encoded</th>\n",
       "      <th>token_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, before, b...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n                          OFFICE...</td>\n",
       "      <td>[(340, 347), (340, 347), (340, 347), (1588, 16...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, HYPERTENS...</td>\n",
       "      <td>286-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\nRecord date: 2091-07-02\\n\\n\\n\\n\\tCAR...</td>\n",
       "      <td>[(555, 569), (555, 569), (555, 569), (2212, 22...</td>\n",
       "      <td>[before, before, before, before, before, HYPER...</td>\n",
       "      <td>237-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\nRecord date: 2122-02-23\\n\\n\\n**The sou...</td>\n",
       "      <td>[(2033, 2043), (2033, 2043), (2033, 2043), (28...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, MEDICATIO...</td>\n",
       "      <td>333-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\nRecord Date: 2070-12-01\\n\\nNarrative His...</td>\n",
       "      <td>[(1834, 1841), (1834, 1841), (1843, 1853), (18...</td>\n",
       "      <td>[before, before, before, MEDICATION, MEDICATIO...</td>\n",
       "      <td>220-03.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>\\n\\n\\nRecord date: 2164-08-24\\n\\n\\n\\n\\t\\t\\tCAR...</td>\n",
       "      <td>[(1734, 1744), (5164, 5173), (1734, 1743), (17...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, MEDICATIO...</td>\n",
       "      <td>227-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>\\n\\n\\nRecord date: 2170-02-17\\n\\n \\n\\nReason f...</td>\n",
       "      <td>[(1138, 1158), (1138, 1158), (1138, 1158), (11...</td>\n",
       "      <td>[HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...</td>\n",
       "      <td>200-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>\\n\\n\\nRecord date: 2170-03-02\\n\\n \\n\\nReason f...</td>\n",
       "      <td>[(1165, 1185), (1165, 1185), (1165, 1185), (11...</td>\n",
       "      <td>[HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...</td>\n",
       "      <td>200-02.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>\\n\\n\\nRecord date: 2171-09-20\\n\\n\\n\\n09/20/217...</td>\n",
       "      <td>[(1343, 1366), (1344, 1364), (1344, 1366), (13...</td>\n",
       "      <td>[before, before, before, HYPERLIPIDEMIA, HYPER...</td>\n",
       "      <td>200-03.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>[before, before, before, HYPERLIPIDEMIA, HYPER...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1304 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              note_text  \\\n",
       "0     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...   \n",
       "1     \\n\\n\\n\\n\\n\\n\\n                          OFFICE...   \n",
       "2     \\n\\n\\n\\n\\nRecord date: 2091-07-02\\n\\n\\n\\n\\tCAR...   \n",
       "3     \\n\\n\\n\\nRecord date: 2122-02-23\\n\\n\\n**The sou...   \n",
       "4     \\n\\n\\nRecord Date: 2070-12-01\\n\\nNarrative His...   \n",
       "...                                                 ...   \n",
       "1299  \\n\\n\\nRecord date: 2164-08-24\\n\\n\\n\\n\\t\\t\\tCAR...   \n",
       "1300  \\n\\n\\nRecord date: 2170-02-17\\n\\n \\n\\nReason f...   \n",
       "1301  \\n\\n\\nRecord date: 2170-03-02\\n\\n \\n\\nReason f...   \n",
       "1302  \\n\\n\\nRecord date: 2171-09-20\\n\\n\\n\\n09/20/217...   \n",
       "1303  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...   \n",
       "\n",
       "                                         evidence_spans  \\\n",
       "0     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "1     [(340, 347), (340, 347), (340, 347), (1588, 16...   \n",
       "2     [(555, 569), (555, 569), (555, 569), (2212, 22...   \n",
       "3     [(2033, 2043), (2033, 2043), (2033, 2043), (28...   \n",
       "4     [(1834, 1841), (1834, 1841), (1843, 1853), (18...   \n",
       "...                                                 ...   \n",
       "1299  [(1734, 1744), (5164, 5173), (1734, 1743), (17...   \n",
       "1300  [(1138, 1158), (1138, 1158), (1138, 1158), (11...   \n",
       "1301  [(1165, 1185), (1165, 1185), (1165, 1185), (11...   \n",
       "1302  [(1343, 1366), (1344, 1364), (1344, 1366), (13...   \n",
       "1303  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "\n",
       "                                                 labels    filename  \\\n",
       "0     [MEDICATION, MEDICATION, MEDICATION, before, b...  292-05.xml   \n",
       "1     [MEDICATION, MEDICATION, MEDICATION, HYPERTENS...  286-04.xml   \n",
       "2     [before, before, before, before, before, HYPER...  237-01.xml   \n",
       "3     [MEDICATION, MEDICATION, MEDICATION, MEDICATIO...  333-01.xml   \n",
       "4     [before, before, before, MEDICATION, MEDICATIO...  220-03.xml   \n",
       "...                                                 ...         ...   \n",
       "1299  [MEDICATION, MEDICATION, MEDICATION, MEDICATIO...  227-05.xml   \n",
       "1300  [HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...  200-01.xml   \n",
       "1301  [HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...  200-02.xml   \n",
       "1302  [before, before, before, HYPERLIPIDEMIA, HYPER...  200-03.xml   \n",
       "1303  [before, before, before, HYPERLIPIDEMIA, HYPER...  200-04.xml   \n",
       "\n",
       "                                          encoded  \\\n",
       "0     [input_ids, token_type_ids, attention_mask]   \n",
       "1     [input_ids, token_type_ids, attention_mask]   \n",
       "2     [input_ids, token_type_ids, attention_mask]   \n",
       "3     [input_ids, token_type_ids, attention_mask]   \n",
       "4     [input_ids, token_type_ids, attention_mask]   \n",
       "...                                           ...   \n",
       "1299  [input_ids, token_type_ids, attention_mask]   \n",
       "1300  [input_ids, token_type_ids, attention_mask]   \n",
       "1301  [input_ids, token_type_ids, attention_mask]   \n",
       "1302  [input_ids, token_type_ids, attention_mask]   \n",
       "1303  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                           token_labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "1299  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1300  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1301  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1302  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1303  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[1304 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tokenizer.decode([x]) for x in notes_df.iloc[787]['encoded']['input_ids']]\n",
    "# print(notes_df.iloc[787]['note_text'])\n",
    "# list(zip([tokenizer.decode([x]) for x in notes_df.iloc[0]['encoded']['input_ids']],notes_df.iloc[0]['token_labels']))\n",
    "# list(zip(notes_df.iloc[0]['evidence_spans'],notes_df.iloc[0]['labels']))\n",
    "# notes_df.iloc[787]['note_text']\n",
    "# notes_df[notes_df['note_text'].apply(lambda x: '66 yo' in x and 'HISTORY' in x)]#.iloc[-1]['note_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-CAD', 'B-DIABETES', 'B-FAMILY_HIST', 'B-HYPERLIPIDEMIA', 'B-HYPERTENSION', 'B-MEDICATION', 'B-OBESE', 'B-PHI', 'B-SMOKER', 'I-CAD', 'I-DIABETES', 'I-FAMILY_HIST', 'I-HYPERLIPIDEMIA', 'I-HYPERTENSION', 'I-MEDICATION', 'I-OBESE', 'I-PHI', 'I-SMOKER', 'O']\n"
     ]
    }
   ],
   "source": [
    "# labels_list = sorted(list(set(unravel(notes_df['token_labels']))))\n",
    "labels_list =['B-CAD', 'B-DIABETES', 'B-FAMILY_HIST', 'B-HYPERLIPIDEMIA', 'B-HYPERTENSION', 'B-MEDICATION', 'B-OBESE', 'B-PHI', 'B-SMOKER', 'I-CAD', 'I-DIABETES', 'I-FAMILY_HIST', 'I-HYPERLIPIDEMIA', 'I-HYPERTENSION', 'I-MEDICATION', 'I-OBESE', 'I-PHI', 'I-SMOKER', 'O']\n",
    "print(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {k:i for i,k in enumerate(labels_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "# import tensorflow as tf\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "# model = TFBertForTokenClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT',from_pt=True, num_labels=len(labels_list))\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "# input_ids = inputs[\"input_ids\"]\n",
    "# inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "# outputs = model(inputs)\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits\n",
    "# model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [list(np.split(lst, range(510, lst.shape[0], 510)))\n",
    "# notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_ids(lst):\n",
    "    lst=lst[1:-1]\n",
    "    chunks=np.split(lst, range(510, len(lst), 510))\n",
    "    ret = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk)<510:\n",
    "            chunk=list(chunk)+[0]*(510-len(chunk))\n",
    "        ret.append( np.array([101]+list(chunk)+[102]))\n",
    "    return ret\n",
    "\n",
    "def chunk_idxs(lst):\n",
    "    lst=lst[1:-1]\n",
    "    chunks=np.split(lst, range(510, len(lst), 510))\n",
    "    ret = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk)<510:\n",
    "            chunk=list(chunk)\n",
    "        ret.append( np.array(list(chunk)))\n",
    "    return ret\n",
    "\n",
    "def chunk_labels(lst):\n",
    "    lst=lst[1:-1]\n",
    "    chunks=np.split(lst, range(510, len(lst), 510))\n",
    "    ret = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk)<510:\n",
    "            chunk=list(chunk)+['O']*(510-len(chunk))\n",
    "        ret.append( np.array(['O']+list(chunk)+['O']))\n",
    "    return ret\n",
    "\n",
    "def chunk_ids_with_overlap(lst):\n",
    "    \n",
    "    if len(lst)<=512:\n",
    "        return chunk_ids(lst)\n",
    "    return chunk_ids(lst)+chunk_ids(lst[256:])\n",
    "def chunk_labels_with_overlap(lst):\n",
    "    if len(lst)<=512:\n",
    "        return chunk_labels(lst)\n",
    "    return chunk_labels(lst)+chunk_labels(lst[256:])\n",
    "\n",
    "def chunk_idx_with_overlap(lst):\n",
    "    if len(lst)<=512:\n",
    "        return chunk_idxs(lst)\n",
    "    return chunk_idxs(lst)+chunk_idxs(lst[256:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_tokens(notes_df['token_labels'].iloc[0])\n",
    "# chunk_ids(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['chunked_tokens'] = notes_df['encoded'].apply(lambda x: chunk_ids_with_overlap(x['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['chunked_labels'] = notes_df['token_labels'].apply(lambda x: chunk_labels_with_overlap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['chunked_idxs'] = notes_df['token_labels'].apply(lambda x: chunk_idx_with_overlap(list(range(len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes_df['encoded'].iloc[0].token_to_chars(1).start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['patient'] = notes_df['filename'].apply(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes_df['patient'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(pd.Series(notes_df['patient'].unique()).sample(30)))\n",
    "val_filenames = ['259-04.xml', '259-03.xml', '357-02.xml', '185-01.xml', '156-01.xml', '337-03.xml', '223-03.xml', '361-02.xml', '128-04.xml', '351-02.xml', '397-02.xml', '121-01.xml', '397-03.xml', '149-02.xml', '329-03.xml', '174-01.xml', '360-03.xml', '128-01.xml', '145-01.xml', '368-03.xml', '282-04.xml', '176-04.xml', '326-03.xml', '148-02.xml', '103-03.xml', '157-03.xml', '304-03.xml', '395-03.xml', '322-05.xml', '333-01.xml']\n",
    "# val_patients = ['366', '255', '365', '256', '129', '174', '294', '274', '123', '105', '287', '367', '185', '146', '144', '320', '333', '142', '224', '270', '297', '324', '171', '276', '298', '151', '225', '305', '332', '397']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=5\n",
    "# j=-1\n",
    "# print(len(notes_df['token_labels'].iloc[i]))\n",
    "# pd.DataFrame(zip([tokenizer.decode([x]) for x in notes_df['chunked_tokens'].iloc[i][j]],notes_df['chunked_labels'].iloc[i][j])).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_text</th>\n",
       "      <th>evidence_spans</th>\n",
       "      <th>labels</th>\n",
       "      <th>filename</th>\n",
       "      <th>encoded</th>\n",
       "      <th>token_labels</th>\n",
       "      <th>chunked_tokens</th>\n",
       "      <th>chunked_labels</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, before, b...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 2885, 117, 11437, 2158, 2625, 18202, 15...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n                          OFFICE...</td>\n",
       "      <td>[(340, 347), (340, 347), (340, 347), (1588, 16...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, HYPERTENS...</td>\n",
       "      <td>286-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1701, 3805, 13936, 5674, 5053, 2430, 11...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\nRecord date: 2091-07-02\\n\\n\\n\\n\\tCAR...</td>\n",
       "      <td>[(555, 569), (555, 569), (555, 569), (2212, 22...</td>\n",
       "      <td>[before, before, before, before, before, HYPER...</td>\n",
       "      <td>237-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 21040, 1475, 118, 5004...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\nRecord date: 2122-02-23\\n\\n\\n**The sou...</td>\n",
       "      <td>[(2033, 2043), (2033, 2043), (2033, 2043), (28...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, MEDICATIO...</td>\n",
       "      <td>333-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 19538, 1477, 118, 5507...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\nRecord Date: 2070-12-01\\n\\nNarrative His...</td>\n",
       "      <td>[(1834, 1841), (1834, 1841), (1843, 1853), (18...</td>\n",
       "      <td>[before, before, before, MEDICATION, MEDICATIO...</td>\n",
       "      <td>220-03.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 21606, 1568, 118, 1367...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>\\n\\n\\nRecord date: 2164-08-24\\n\\n\\n\\n\\t\\t\\tCAR...</td>\n",
       "      <td>[(1734, 1744), (5164, 5173), (1734, 1743), (17...</td>\n",
       "      <td>[MEDICATION, MEDICATION, MEDICATION, MEDICATIO...</td>\n",
       "      <td>227-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 22148, 1527, 118, 4775...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>\\n\\n\\nRecord date: 2170-02-17\\n\\n \\n\\nReason f...</td>\n",
       "      <td>[(1138, 1158), (1138, 1158), (1138, 1158), (11...</td>\n",
       "      <td>[HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...</td>\n",
       "      <td>200-01.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 22196, 1568, 118, 5507...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>\\n\\n\\nRecord date: 2170-03-02\\n\\n \\n\\nReason f...</td>\n",
       "      <td>[(1165, 1185), (1165, 1185), (1165, 1185), (11...</td>\n",
       "      <td>[HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...</td>\n",
       "      <td>200-02.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 22196, 1568, 118, 5347...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>\\n\\n\\nRecord date: 2171-09-20\\n\\n\\n\\n09/20/217...</td>\n",
       "      <td>[(1343, 1366), (1344, 1364), (1344, 1366), (13...</td>\n",
       "      <td>[before, before, before, HYPERLIPIDEMIA, HYPER...</td>\n",
       "      <td>200-03.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 22196, 1475, 118, 4925...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>[before, before, before, HYPERLIPIDEMIA, HYPER...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[101, 1647, 2236, 131, 22196, 1495, 118, 5507...</td>\n",
       "      <td>[[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1304 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              note_text  \\\n",
       "0     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...   \n",
       "1     \\n\\n\\n\\n\\n\\n\\n                          OFFICE...   \n",
       "2     \\n\\n\\n\\n\\nRecord date: 2091-07-02\\n\\n\\n\\n\\tCAR...   \n",
       "3     \\n\\n\\n\\nRecord date: 2122-02-23\\n\\n\\n**The sou...   \n",
       "4     \\n\\n\\nRecord Date: 2070-12-01\\n\\nNarrative His...   \n",
       "...                                                 ...   \n",
       "1299  \\n\\n\\nRecord date: 2164-08-24\\n\\n\\n\\n\\t\\t\\tCAR...   \n",
       "1300  \\n\\n\\nRecord date: 2170-02-17\\n\\n \\n\\nReason f...   \n",
       "1301  \\n\\n\\nRecord date: 2170-03-02\\n\\n \\n\\nReason f...   \n",
       "1302  \\n\\n\\nRecord date: 2171-09-20\\n\\n\\n\\n09/20/217...   \n",
       "1303  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...   \n",
       "\n",
       "                                         evidence_spans  \\\n",
       "0     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "1     [(340, 347), (340, 347), (340, 347), (1588, 16...   \n",
       "2     [(555, 569), (555, 569), (555, 569), (2212, 22...   \n",
       "3     [(2033, 2043), (2033, 2043), (2033, 2043), (28...   \n",
       "4     [(1834, 1841), (1834, 1841), (1843, 1853), (18...   \n",
       "...                                                 ...   \n",
       "1299  [(1734, 1744), (5164, 5173), (1734, 1743), (17...   \n",
       "1300  [(1138, 1158), (1138, 1158), (1138, 1158), (11...   \n",
       "1301  [(1165, 1185), (1165, 1185), (1165, 1185), (11...   \n",
       "1302  [(1343, 1366), (1344, 1364), (1344, 1366), (13...   \n",
       "1303  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "\n",
       "                                                 labels    filename  \\\n",
       "0     [MEDICATION, MEDICATION, MEDICATION, before, b...  292-05.xml   \n",
       "1     [MEDICATION, MEDICATION, MEDICATION, HYPERTENS...  286-04.xml   \n",
       "2     [before, before, before, before, before, HYPER...  237-01.xml   \n",
       "3     [MEDICATION, MEDICATION, MEDICATION, MEDICATIO...  333-01.xml   \n",
       "4     [before, before, before, MEDICATION, MEDICATIO...  220-03.xml   \n",
       "...                                                 ...         ...   \n",
       "1299  [MEDICATION, MEDICATION, MEDICATION, MEDICATIO...  227-05.xml   \n",
       "1300  [HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...  200-01.xml   \n",
       "1301  [HYPERLIPIDEMIA, HYPERLIPIDEMIA, HYPERLIPIDEMI...  200-02.xml   \n",
       "1302  [before, before, before, HYPERLIPIDEMIA, HYPER...  200-03.xml   \n",
       "1303  [before, before, before, HYPERLIPIDEMIA, HYPER...  200-04.xml   \n",
       "\n",
       "                                          encoded  \\\n",
       "0     [input_ids, token_type_ids, attention_mask]   \n",
       "1     [input_ids, token_type_ids, attention_mask]   \n",
       "2     [input_ids, token_type_ids, attention_mask]   \n",
       "3     [input_ids, token_type_ids, attention_mask]   \n",
       "4     [input_ids, token_type_ids, attention_mask]   \n",
       "...                                           ...   \n",
       "1299  [input_ids, token_type_ids, attention_mask]   \n",
       "1300  [input_ids, token_type_ids, attention_mask]   \n",
       "1301  [input_ids, token_type_ids, attention_mask]   \n",
       "1302  [input_ids, token_type_ids, attention_mask]   \n",
       "1303  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                           token_labels  \\\n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                 ...   \n",
       "1299  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1300  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1301  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1302  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1303  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                         chunked_tokens  \\\n",
       "0     [[101, 2885, 117, 11437, 2158, 2625, 18202, 15...   \n",
       "1     [[101, 1701, 3805, 13936, 5674, 5053, 2430, 11...   \n",
       "2     [[101, 1647, 2236, 131, 21040, 1475, 118, 5004...   \n",
       "3     [[101, 1647, 2236, 131, 19538, 1477, 118, 5507...   \n",
       "4     [[101, 1647, 2236, 131, 21606, 1568, 118, 1367...   \n",
       "...                                                 ...   \n",
       "1299  [[101, 1647, 2236, 131, 22148, 1527, 118, 4775...   \n",
       "1300  [[101, 1647, 2236, 131, 22196, 1568, 118, 5507...   \n",
       "1301  [[101, 1647, 2236, 131, 22196, 1568, 118, 5347...   \n",
       "1302  [[101, 1647, 2236, 131, 22196, 1475, 118, 4925...   \n",
       "1303  [[101, 1647, 2236, 131, 22196, 1495, 118, 5507...   \n",
       "\n",
       "                                         chunked_labels patient  \n",
       "0     [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     292  \n",
       "1     [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     286  \n",
       "2     [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     237  \n",
       "3     [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     333  \n",
       "4     [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     220  \n",
       "...                                                 ...     ...  \n",
       "1299  [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     227  \n",
       "1300  [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     200  \n",
       "1301  [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     200  \n",
       "1302  [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     200  \n",
       "1303  [[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...     200  \n",
       "\n",
       "[1304 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [292-05.xml292-05.xml292-05.xml292-05.xml292-0...\n",
       "1                        [286-04.xml286-04.xml286-04.xml]\n",
       "2       [237-01.xml237-01.xml237-01.xml237-01.xml237-0...\n",
       "3       [333-01.xml333-01.xml333-01.xml333-01.xml333-0...\n",
       "4       [220-03.xml220-03.xml220-03.xml220-03.xml220-0...\n",
       "                              ...                        \n",
       "1299    [227-05.xml227-05.xml227-05.xml227-05.xml227-0...\n",
       "1300    [200-01.xml200-01.xml200-01.xml200-01.xml200-0...\n",
       "1301    [200-02.xml200-02.xml200-02.xml200-02.xml200-0...\n",
       "1302           [200-03.xml200-03.xml200-03.xml200-03.xml]\n",
       "1303    [200-04.xml200-04.xml200-04.xml200-04.xml200-0...\n",
       "Length: 1304, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notes_df['encoded'].iloc[2]\n",
    "notes_df.apply(lambda row: [row['filename']*len(row['chunked_labels'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(list(zip(unravel(notes_df['chunked_tokens']), unravel(notes_df['chunked_labels']),  unravel(notes_df['chunked_idxs']))) , columns=['chunked_tokens','chunked_labels', 'chunked_idxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label_ids'] = train_data['chunked_labels'].apply(lambda x: [labels_dict[y] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['filename']=unravel(unravel(notes_df.apply(lambda row: [[row['filename']]*len(row['chunked_labels'])],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['note_text']=unravel(unravel(notes_df.apply(lambda row: [[row['note_text']]*len(row['chunked_labels'])],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['encoded']=unravel(unravel(notes_df.apply(lambda row: [[row['encoded']]*len(row['chunked_labels'])],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['evidence_spans']=unravel(unravel(notes_df.apply(lambda row: [[row['evidence_spans']]*len(row['chunked_labels'])],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['labels']=unravel(unravel(notes_df.apply(lambda row: [[row['labels']]*len(row['chunked_labels'])],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['HYPERLIPIDEMIA', 'HYPERLIPIDEMIA', 'HYPERLIPIDEMIA', 'HYPERLIPIDEMIA', 'HYPERLIPIDEMIA', 'HYPERLIPIDEMIA', 'before', 'before', 'before', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'before', 'before', 'before', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'before', 'before', 'before', 'MEDICATION', 'MEDICATION', 'MEDICATION', 'before', 'before', 'before', 'before', 'before', 'before', 'HYPERTENSION', 'HYPERTENSION', 'HYPERTENSION', 'HYPERTENSION', 'HYPERTENSION', 'HYPERTENSION', 'before', 'before', 'before', 'before', 'DIABETES', 'DIABETES', 'DIABETES', 'before', 'before', 'before', 'DIABETES', 'DIABETES', 'DIABETES'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df[notes_df['filename']=='185-01.xml']['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_dict = {'input_ids':np.array([x for x in train_data[train_data['filename'].apply( lambda x: x not in val_filenames)]['chunked_tokens']])}\n",
    "val_inputs_dict = {'input_ids':np.array([x for x in train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['chunked_tokens']])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunked_tokens</th>\n",
       "      <th>chunked_labels</th>\n",
       "      <th>chunked_idxs</th>\n",
       "      <th>label_ids</th>\n",
       "      <th>filename</th>\n",
       "      <th>encoded</th>\n",
       "      <th>evidence_spans</th>\n",
       "      <th>note_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2885, 117, 11437, 2158, 2625, 18202, 158...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 8184, 1146, 117, 1117, 1250, 3750, 1144,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[511, 512, 513, 514, 515, 516, 517, 518, 519, ...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 1144, 1793, 1105, 2604, 170, 3443, 1104,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1021, 1022, 1023, 1024, 1025, 1026, 1027, 102...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 178, 6639, 1643, 1105, 9233, 1920, 11437...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[257, 258, 259, 260, 261, 262, 263, 264, 265, ...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 117, 1868, 17030, 10399, 4214, 17713, 18...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[767, 768, 769, 770, 771, 772, 773, 774, 775, ...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>292-05.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2819), (2811, 2819), (2811, 2819), (40...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>[101, 27466, 1306, 11509, 19756, 1394, 1406, 1...</td>\n",
       "      <td>[O, B-MEDICATION, I-MEDICATION, I-MEDICATION, ...</td>\n",
       "      <td>[1021, 1022, 1023, 1024, 1025, 1026, 1027, 102...</td>\n",
       "      <td>[18, 5, 14, 14, 14, 14, 18, 18, 18, 18, 18, 18...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>[101, 1189, 1111, 1140, 1106, 1129, 1562, 1120...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1531, 1532, 1533, 1534, 1535, 1536, 1537, 153...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>[101, 170, 5581, 1214, 118, 1385, 12400, 1114,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-SMOKER, I-SMOKER...</td>\n",
       "      <td>[257, 258, 259, 260, 261, 262, 263, 264, 265, ...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 8, 17, 17...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>[101, 185, 188, 5208, 1204, 22148, 1527, 6320,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[767, 768, 769, 770, 771, 772, 773, 774, 775, ...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>[101, 3452, 131, 1679, 17670, 117, 174, 18882,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1277, 1278, 1279, 1280, 1281, 1282, 1283, 128...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
       "      <td>200-04.xml</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[(2811, 2831), (2811, 2831), (2811, 2831), (28...</td>\n",
       "      <td>\\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6455 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         chunked_tokens  \\\n",
       "0     [101, 2885, 117, 11437, 2158, 2625, 18202, 158...   \n",
       "1     [101, 8184, 1146, 117, 1117, 1250, 3750, 1144,...   \n",
       "2     [101, 1144, 1793, 1105, 2604, 170, 3443, 1104,...   \n",
       "3     [101, 178, 6639, 1643, 1105, 9233, 1920, 11437...   \n",
       "4     [101, 117, 1868, 17030, 10399, 4214, 17713, 18...   \n",
       "...                                                 ...   \n",
       "6450  [101, 27466, 1306, 11509, 19756, 1394, 1406, 1...   \n",
       "6451  [101, 1189, 1111, 1140, 1106, 1129, 1562, 1120...   \n",
       "6452  [101, 170, 5581, 1214, 118, 1385, 12400, 1114,...   \n",
       "6453  [101, 185, 188, 5208, 1204, 22148, 1527, 6320,...   \n",
       "6454  [101, 3452, 131, 1679, 17670, 117, 174, 18882,...   \n",
       "\n",
       "                                         chunked_labels  \\\n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                 ...   \n",
       "6450  [O, B-MEDICATION, I-MEDICATION, I-MEDICATION, ...   \n",
       "6451  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "6452  [O, O, O, O, O, O, O, O, O, B-SMOKER, I-SMOKER...   \n",
       "6453  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "6454  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                           chunked_idxs  \\\n",
       "0     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1     [511, 512, 513, 514, 515, 516, 517, 518, 519, ...   \n",
       "2     [1021, 1022, 1023, 1024, 1025, 1026, 1027, 102...   \n",
       "3     [257, 258, 259, 260, 261, 262, 263, 264, 265, ...   \n",
       "4     [767, 768, 769, 770, 771, 772, 773, 774, 775, ...   \n",
       "...                                                 ...   \n",
       "6450  [1021, 1022, 1023, 1024, 1025, 1026, 1027, 102...   \n",
       "6451  [1531, 1532, 1533, 1534, 1535, 1536, 1537, 153...   \n",
       "6452  [257, 258, 259, 260, 261, 262, 263, 264, 265, ...   \n",
       "6453  [767, 768, 769, 770, 771, 772, 773, 774, 775, ...   \n",
       "6454  [1277, 1278, 1279, 1280, 1281, 1282, 1283, 128...   \n",
       "\n",
       "                                              label_ids    filename  \\\n",
       "0     [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  292-05.xml   \n",
       "1     [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  292-05.xml   \n",
       "2     [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  292-05.xml   \n",
       "3     [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  292-05.xml   \n",
       "4     [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  292-05.xml   \n",
       "...                                                 ...         ...   \n",
       "6450  [18, 5, 14, 14, 14, 14, 18, 18, 18, 18, 18, 18...  200-04.xml   \n",
       "6451  [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  200-04.xml   \n",
       "6452  [18, 18, 18, 18, 18, 18, 18, 18, 18, 8, 17, 17...  200-04.xml   \n",
       "6453  [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  200-04.xml   \n",
       "6454  [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...  200-04.xml   \n",
       "\n",
       "                                          encoded  \\\n",
       "0     [input_ids, token_type_ids, attention_mask]   \n",
       "1     [input_ids, token_type_ids, attention_mask]   \n",
       "2     [input_ids, token_type_ids, attention_mask]   \n",
       "3     [input_ids, token_type_ids, attention_mask]   \n",
       "4     [input_ids, token_type_ids, attention_mask]   \n",
       "...                                           ...   \n",
       "6450  [input_ids, token_type_ids, attention_mask]   \n",
       "6451  [input_ids, token_type_ids, attention_mask]   \n",
       "6452  [input_ids, token_type_ids, attention_mask]   \n",
       "6453  [input_ids, token_type_ids, attention_mask]   \n",
       "6454  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                         evidence_spans  \\\n",
       "0     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "1     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "2     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "3     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "4     [(2811, 2819), (2811, 2819), (2811, 2819), (40...   \n",
       "...                                                 ...   \n",
       "6450  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "6451  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "6452  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "6453  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "6454  [(2811, 2831), (2811, 2831), (2811, 2831), (28...   \n",
       "\n",
       "                                              note_text  \n",
       "0     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...  \n",
       "1     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...  \n",
       "2     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...  \n",
       "3     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...  \n",
       "4     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHALL, NICK\\n\\n65219816\\n\\n...  \n",
       "...                                                 ...  \n",
       "6450  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...  \n",
       "6451  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...  \n",
       "6452  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...  \n",
       "6453  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...  \n",
       "6454  \\n\\n\\nRecord date: 2173-02-04\\n\\n\\nRADIATION O...  \n",
       "\n",
       "[6455 rows x 8 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[train_data['filename'].apply( lambda x: x not in val_filenames)].to_csv('datasets/n2c2_train_dataset.csv')\n",
    "# train_data[train_data['filename'].apply( lambda x: x in val_filenames)].to_csv('datasets/n2c2_val_dataset.csv')\n",
    "train_data[train_data['filename'].apply( lambda x: x not in val_filenames)].to_pickle('datasets/n2c2_train_dataset.pk')\n",
    "train_data[train_data['filename'].apply( lambda x: x in val_filenames)].to_pickle('datasets/n2c2_val_dataset.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict([[[row] for row in train_inputs_dict['input_ids']],list(train_data[train_data['filename'].apply( lambda x: x not in val_filenames)]['label_ids'])  ]).transpose().to_csv('datasets/n2c2_train_dataset.csv', header=['tokens','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict([[[row] for row in val_inputs_dict['input_ids']],list(train_data[train_data['filename'].apply( lambda x: x not in val_filenames)]['label_ids'])  ]).transpose().to_csv('datasets/n2c2_val_dataset.csv', header=['tokens','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=767\n",
    "# j=-1\n",
    "# pd.DataFrame(list(zip([tokenizer.decode([x]) for x in notes_df.iloc[i]['chunked_tokens'][j]],notes_df.iloc[i]['chunked_labels'][j]))).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_inputs_dict,\n",
    "    list(train_data[train_data['filename'].apply( lambda x: x not in val_filenames)]['label_ids'])\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    val_inputs_dict,\n",
    "    list(train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['label_ids'])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-87c274e588eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer =  tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08, clipnorm=1)\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    def __init__(self):\n",
    "         pass\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "#         try:\n",
    "        self.model.save_pretrained('NER/models/bert_base_cased'+str(epoch)+'.h5')\n",
    "#         except Exception as e:\n",
    "#             print(concept, e)\n",
    "#             warnings.warn(concept+' '+str(e))\n",
    "metrics_callback = MetricsCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_dataset,steps_per_epoch=1, epochs=5,validation_data=val_dataset,callbacks=[metrics_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at NER/models/clinicalbert_batchsize8_2.h5 were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at NER/models/clinicalbert_batchsize8_2.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForTokenClassification.from_pretrained('NER/models/clinicalbert_batchsize8_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2aaab2bb6590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x2aaab3b58b38> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2aaab2bb6590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x2aaab3b58b38> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "outputs=model.predict(val_dataset.batch(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 512, 31)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(outputs[0], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list =['B-CAD', 'B-DIABETES', 'B-FAMILY_HIST', 'B-HYPERLIPIDEMIA', 'B-HYPERTENSION', 'B-MEDICATION', 'B-OBESE', 'B-PHI', 'B-SMOKER', 'I-CAD', 'I-DIABETES', 'I-FAMILY_HIST', 'I-HYPERLIPIDEMIA', 'I-HYPERTENSION', 'I-MEDICATION', 'I-OBESE', 'I-PHI', 'I-SMOKER', 'O']\n",
    "\n",
    "# labels_list = ['I-PHI', 'I-SMOKERever', 'I-MEDICATIONdiuretic', 'I-MEDICATIONARB', 'I-MEDICATIONmetformin', 'I-CAD', 'I-SMOKERpast', 'I-SMOKERnever', 'I-MEDICATIONanti diabetes', 'I-HYPERLIPIDEMIA', 'I-MEDICATIONezetimibe', 'I-FAMILY_HIST', 'I-MEDICATIONniacin', 'I-MEDICATIONinsulin', 'I-MEDICATIONthienopyridine', 'I-MEDICATIONnitrate', 'I-MEDICATIONthiazolidinedione', 'I-MEDICATIONaspirin', 'I-MEDICATIONstatin', 'I-HYPERTENSION', 'I-MEDICATIONcalcium channel blocker', 'I-MEDICATIONACE inhibitor', 'I-MEDICATIONDPP4 inhibitors', 'I-MEDICATIONsulfonylureas', 'I-DIABETES', 'O', 'I-MEDICATIONbeta blocker', 'I-SMOKERcurrent', 'I-OBESE', 'I-SMOKERunknown', 'I-MEDICATIONfibrate']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_labels_dict = {i:k for i,k in enumerate(labels_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_exs=int(predictions.numpy().shape[0]/512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_results_df = pd.DataFrame([list(predictions.numpy().reshape([num_val_exs,512]))]).transpose()\n",
    "val_results_df = pd.DataFrame([list(predictions.numpy())]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9       [101, 1647, 2236, 131, 19538, 1477, 118, 5507,...\n",
       "10      [101, 116, 120, 8347, 1358, 191, 2875, 1181, 1...\n",
       "11      [101, 1406, 120, 19538, 1477, 14516, 9238, 215...\n",
       "12      [101, 120, 188, 1477, 119, 1103, 1762, 1110, 2...\n",
       "13      [101, 5674, 14046, 20504, 119, 1156, 5257, 112...\n",
       "                              ...                        \n",
       "3811    [101, 1647, 2236, 131, 18615, 1568, 118, 4925,...\n",
       "3812    [101, 9097, 120, 8710, 1106, 2584, 9964, 117, ...\n",
       "3813    [101, 2047, 2052, 117, 1649, 1119, 1110, 2218,...\n",
       "3814    [101, 117, 176, 1193, 19364, 3269, 117, 181, 2...\n",
       "3815    [101, 3179, 1496, 1106, 2489, 119, 1119, 1674,...\n",
       "Name: chunked_tokens, Length: 132, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['chunked_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_df['tokens'] = list(train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['chunked_tokens'].apply(lambda x: [tokenizer.decode([y]) for y in x]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_df.columns=['class_nums','tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_df['classes']=val_results_df['class_nums'].apply(lambda x: [reverse_labels_dict[y] for y in x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = np.concatenate([y for x, y in val_dataset], axis=0).reshape(132,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [25, 25, 25, 25, 0, 0, 0, 0, 0, 0, 25, 25, 25,...\n",
       "1      [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "2      [25, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "3      [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "4      [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "                             ...                        \n",
       "127    [25, 29, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "128    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "129    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "130    [25, 18, 23, 23, 23, 23, 23, 21, 21, 21, 21, 2...\n",
       "131    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...\n",
       "Length: 132, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_df['token_labels'] = pd.Series(list(val_y)).apply(lambda x: [reverse_labels_dict[y] for y in x])#list(train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['chunked_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_df['filename'] = list(train_data[train_data['filename'].apply( lambda x: x in val_filenames)]['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_nums</th>\n",
       "      <th>tokens</th>\n",
       "      <th>classes</th>\n",
       "      <th>token_labels</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25, 25, 25, 25, 0, 0, 0, 0, 0, 0, 25, 25, 25,...</td>\n",
       "      <td>[[CLS], record, date, :, 212, ##2, -, 02, -, 2...</td>\n",
       "      <td>[O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...</td>\n",
       "      <td>[O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...</td>\n",
       "      <td>333-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], +, /, 125, ##u, v, ##it, ##d, ), 250, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>333-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], 20, /, 212, ##2, se, ##nn, ##os, ##ide...</td>\n",
       "      <td>[O, I-PHI, I-PHI, I-PHI, I-PHI, O, O, O, O, O,...</td>\n",
       "      <td>[O, I-PHI, I-PHI, I-PHI, I-PHI, O, O, O, O, O,...</td>\n",
       "      <td>333-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], /, s, ##2, ., the, heart, is, regular,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-P...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-P...</td>\n",
       "      <td>333-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], ##po, ##kal, ##emia, ., would, benefit...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>333-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>[25, 25, 25, 25, 25, 0, 25, 0, 0, 0, 0, 25, 0,...</td>\n",
       "      <td>[[CLS], record, date, :, 215, ##0, -, 09, -, 0...</td>\n",
       "      <td>[O, O, O, O, O, I-PHI, O, I-PHI, I-PHI, I-PHI,...</td>\n",
       "      <td>[O, I-SMOKERunknown, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>185-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], circulation, /, sensation, to, legs, i...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>185-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], ##ri, today, ,, however, he, is, certa...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>185-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>[25, 25, 23, 23, 23, 23, 25, 21, 21, 21, 21, 2...</td>\n",
       "      <td>[[CLS], ,, g, ##ly, ##bur, ##ide, ,, l, ##isi,...</td>\n",
       "      <td>[O, O, I-MEDICATIONsulfonylureas, I-MEDICATION...</td>\n",
       "      <td>[O, I-MEDICATIONstatin, I-MEDICATIONsulfonylur...</td>\n",
       "      <td>185-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "      <td>[[CLS], walking, due, to, pain, ., he, does, n...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>185-01.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            class_nums  \\\n",
       "0    [25, 25, 25, 25, 0, 0, 0, 0, 0, 0, 25, 25, 25,...   \n",
       "1    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "2    [25, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "3    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "4    [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "..                                                 ...   \n",
       "127  [25, 25, 25, 25, 25, 0, 25, 0, 0, 0, 0, 25, 0,...   \n",
       "128  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "129  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "130  [25, 25, 23, 23, 23, 23, 25, 21, 21, 21, 21, 2...   \n",
       "131  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [[CLS], record, date, :, 212, ##2, -, 02, -, 2...   \n",
       "1    [[CLS], +, /, 125, ##u, v, ##it, ##d, ), 250, ...   \n",
       "2    [[CLS], 20, /, 212, ##2, se, ##nn, ##os, ##ide...   \n",
       "3    [[CLS], /, s, ##2, ., the, heart, is, regular,...   \n",
       "4    [[CLS], ##po, ##kal, ##emia, ., would, benefit...   \n",
       "..                                                 ...   \n",
       "127  [[CLS], record, date, :, 215, ##0, -, 09, -, 0...   \n",
       "128  [[CLS], circulation, /, sensation, to, legs, i...   \n",
       "129  [[CLS], ##ri, today, ,, however, he, is, certa...   \n",
       "130  [[CLS], ,, g, ##ly, ##bur, ##ide, ,, l, ##isi,...   \n",
       "131  [[CLS], walking, due, to, pain, ., he, does, n...   \n",
       "\n",
       "                                               classes  \\\n",
       "0    [O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...   \n",
       "1    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2    [O, I-PHI, I-PHI, I-PHI, I-PHI, O, O, O, O, O,...   \n",
       "3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-P...   \n",
       "4    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "..                                                 ...   \n",
       "127  [O, O, O, O, O, I-PHI, O, I-PHI, I-PHI, I-PHI,...   \n",
       "128  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "129  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "130  [O, O, I-MEDICATIONsulfonylureas, I-MEDICATION...   \n",
       "131  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                          token_labels    filename  \n",
       "0    [O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...  333-01.xml  \n",
       "1    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  333-01.xml  \n",
       "2    [O, I-PHI, I-PHI, I-PHI, I-PHI, O, O, O, O, O,...  333-01.xml  \n",
       "3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-P...  333-01.xml  \n",
       "4    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  333-01.xml  \n",
       "..                                                 ...         ...  \n",
       "127  [O, I-SMOKERunknown, O, O, O, O, O, O, O, O, O...  185-01.xml  \n",
       "128  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  185-01.xml  \n",
       "129  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  185-01.xml  \n",
       "130  [O, I-MEDICATIONstatin, I-MEDICATIONsulfonylur...  185-01.xml  \n",
       "131  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  185-01.xml  \n",
       "\n",
       "[132 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, classification_report\n",
    "recall = recall_score( unravel(list(val_y)),unravel(val_results_df['class_nums']),  average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7128200925881945"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                              I-CAD     0.5208    0.6897    0.5935       145\n",
      "                         I-DIABETES     0.6879    0.8963    0.7784       241\n",
      "                      I-FAMILY_HIST     0.3000    0.6000    0.4000        15\n",
      "                   I-HYPERLIPIDEMIA     0.8837    0.8398    0.8612       181\n",
      "                     I-HYPERTENSION     0.8253    0.8427    0.8339       426\n",
      "          I-MEDICATIONACE inhibitor     0.8908    0.7737    0.8281       137\n",
      "                    I-MEDICATIONARB     0.6842    0.5652    0.6190        23\n",
      "                I-MEDICATIONaspirin     0.9167    0.6000    0.7253       110\n",
      "           I-MEDICATIONbeta blocker     0.7654    0.7561    0.7607       164\n",
      "I-MEDICATIONcalcium channel blocker     0.8202    0.9605    0.8848        76\n",
      "               I-MEDICATIONdiuretic     1.0000    0.6757    0.8065        37\n",
      "                I-MEDICATIONfibrate     0.0000    0.0000    0.0000         6\n",
      "                I-MEDICATIONinsulin     0.6174    0.6893    0.6514       103\n",
      "              I-MEDICATIONmetformin     1.0000    0.7500    0.8571        72\n",
      "                I-MEDICATIONnitrate     0.5000    0.8667    0.6341        15\n",
      "                 I-MEDICATIONstatin     0.9217    0.8480    0.8833       125\n",
      "          I-MEDICATIONsulfonylureas     0.9474    0.6545    0.7742        55\n",
      "      I-MEDICATIONthiazolidinedione     0.7500    1.0000    0.8571        12\n",
      "         I-MEDICATIONthienopyridine     0.6279    1.0000    0.7714        27\n",
      "                            I-OBESE     0.4643    1.0000    0.6341        26\n",
      "                              I-PHI     0.7414    0.8706    0.8008      2512\n",
      "                    I-SMOKERcurrent     0.8125    0.1512    0.2549        86\n",
      "                      I-SMOKERnever     0.6000    0.7674    0.6735        43\n",
      "                       I-SMOKERpast     0.5607    0.6452    0.6000        93\n",
      "                    I-SMOKERunknown     0.1538    0.1111    0.1290        18\n",
      "                                  O     0.9872    0.9796    0.9834     62836\n",
      "\n",
      "                           accuracy                         0.9683     67584\n",
      "                          macro avg     0.6915    0.7128    0.6768     67584\n",
      "                       weighted avg     0.9709    0.9683    0.9688     67584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(unravel(val_results_df['token_labels']),unravel(list(val_results_df['classes'])),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_level_stats(labels, preds):\n",
    "    doc_preds = [[label in preds[i] for label in labels_list] for i in range(len(preds))]\n",
    "    doc_labels = [[label in labels[i] for label in labels_list] for i in range(len(preds))]\n",
    "    print(classification_report(doc_labels, doc_preds, target_names=labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                              I-PHI       0.66      0.87      0.75        78\n",
      "                       I-SMOKERever       0.00      0.00      0.00         0\n",
      "               I-MEDICATIONdiuretic       1.00      1.00      1.00         5\n",
      "                    I-MEDICATIONARB       0.60      1.00      0.75         3\n",
      "              I-MEDICATIONmetformin       1.00      1.00      1.00        14\n",
      "                              I-CAD       0.83      1.00      0.91        10\n",
      "                       I-SMOKERpast       0.44      0.78      0.56         9\n",
      "                      I-SMOKERnever       0.73      1.00      0.85        11\n",
      "          I-MEDICATIONanti diabetes       0.00      0.00      0.00         0\n",
      "                   I-HYPERLIPIDEMIA       0.90      0.96      0.93        27\n",
      "              I-MEDICATIONezetimibe       0.00      0.00      0.00         0\n",
      "                      I-FAMILY_HIST       0.67      0.67      0.67         3\n",
      "                 I-MEDICATIONniacin       0.00      0.00      0.00         0\n",
      "                I-MEDICATIONinsulin       1.00      0.94      0.97        17\n",
      "         I-MEDICATIONthienopyridine       0.78      1.00      0.88         7\n",
      "                I-MEDICATIONnitrate       0.71      1.00      0.83         5\n",
      "      I-MEDICATIONthiazolidinedione       0.67      1.00      0.80         4\n",
      "                I-MEDICATIONaspirin       0.93      1.00      0.96        25\n",
      "                 I-MEDICATIONstatin       0.94      0.97      0.95        31\n",
      "                     I-HYPERTENSION       0.91      0.96      0.94        53\n",
      "I-MEDICATIONcalcium channel blocker       0.82      0.95      0.88        19\n",
      "          I-MEDICATIONACE inhibitor       0.91      0.84      0.87        25\n",
      "        I-MEDICATIONDPP4 inhibitors       0.00      0.00      0.00         0\n",
      "          I-MEDICATIONsulfonylureas       1.00      0.64      0.78        14\n",
      "                         I-DIABETES       0.78      1.00      0.88        39\n",
      "                                  O       1.00      1.00      1.00       132\n",
      "           I-MEDICATIONbeta blocker       0.87      0.87      0.87        30\n",
      "                    I-SMOKERcurrent       0.80      0.36      0.50        11\n",
      "                            I-OBESE       0.60      1.00      0.75         9\n",
      "                    I-SMOKERunknown       0.46      0.46      0.46        13\n",
      "                I-MEDICATIONfibrate       0.00      0.00      0.00         2\n",
      "\n",
      "                          micro avg       0.84      0.92      0.88       596\n",
      "                          macro avg       0.65      0.72      0.67       596\n",
      "                       weighted avg       0.85      0.92      0.88       596\n",
      "                        samples avg       0.83      0.92      0.86       596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_level_stats(val_results_df['token_labels'],list(val_results_df['classes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI...\n",
       "1  [O, O, O, O, I-PHI, I-PHI, I-PHI, I-PHI, I-PHI..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(( unravel(val_results_df['token_labels']),unravel(list(val_results_df['classes'])) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_labels</th>\n",
       "      <th>token_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lab</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##etal</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##ol</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o</td>\n",
       "      <td>I-MEDICATIONbeta blocker</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>patient</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blood</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pressure</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>went</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>down</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>140</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>prior</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>to</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>admission</td>\n",
       "      <td>I-HYPERTENSION</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>patient</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>primary</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>care</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>physician</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>who</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>agreed</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>admission</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>medical</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>service</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>di</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>##ag</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>##nose</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>##s</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tokens              token_labels               token_preds\n",
       "0       [CLS]                         O                         O\n",
       "1          of  I-MEDICATIONbeta blocker                         O\n",
       "2         lab  I-MEDICATIONbeta blocker  I-MEDICATIONbeta blocker\n",
       "3      ##etal  I-MEDICATIONbeta blocker  I-MEDICATIONbeta blocker\n",
       "4        ##ol  I-MEDICATIONbeta blocker  I-MEDICATIONbeta blocker\n",
       "5           p  I-MEDICATIONbeta blocker                         O\n",
       "6           .  I-MEDICATIONbeta blocker                         O\n",
       "7           o  I-MEDICATIONbeta blocker                         O\n",
       "8           .                         O                         O\n",
       "9         the            I-HYPERTENSION                         O\n",
       "10    patient            I-HYPERTENSION                         O\n",
       "11          '            I-HYPERTENSION                         O\n",
       "12          s            I-HYPERTENSION                         O\n",
       "13      blood            I-HYPERTENSION            I-HYPERTENSION\n",
       "14   pressure            I-HYPERTENSION            I-HYPERTENSION\n",
       "15       went            I-HYPERTENSION                         O\n",
       "16       down            I-HYPERTENSION                         O\n",
       "17         to            I-HYPERTENSION            I-HYPERTENSION\n",
       "18        140            I-HYPERTENSION            I-HYPERTENSION\n",
       "19          /            I-HYPERTENSION            I-HYPERTENSION\n",
       "20         82            I-HYPERTENSION            I-HYPERTENSION\n",
       "21      prior            I-HYPERTENSION                         O\n",
       "22         to            I-HYPERTENSION                         O\n",
       "23  admission            I-HYPERTENSION                         O\n",
       "24          .                         O                         O\n",
       "25        the                         O                         O\n",
       "26    patient                         O                         O\n",
       "27          '                         O                         O\n",
       "28          s                         O                         O\n",
       "29    primary                         O                         O\n",
       "30       care                         O                         O\n",
       "31  physician                         O                         O\n",
       "32        was                         O                         O\n",
       "33     called                         O                         O\n",
       "34        who                         O                         O\n",
       "35     agreed                         O                         O\n",
       "36       with                         O                         O\n",
       "37        the                         O                         O\n",
       "38  admission                         O                         O\n",
       "39         to                         O                         O\n",
       "40        the                         O                         O\n",
       "41    medical                         O                         O\n",
       "42    service                         O                         O\n",
       "43          .                         O                         O\n",
       "44         di                         O                         O\n",
       "45       ##ag                         O                         O\n",
       "46     ##nose                         O                         O\n",
       "47        ##s                         O                         O\n",
       "48          :                         O                         O\n",
       "49          1                         O                         O"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 21\n",
    "pd.DataFrame(list(zip(val_results_df.iloc[i]['tokens'],val_results_df.iloc[i]['token_labels'], val_results_df.iloc[i]['classes'])), columns=['tokens', 'token_labels', 'token_preds']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_notes = pd.read_csv('../../../LHC_mimic/mimic3_1.4/raw_data/NOTEEVENTS.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20</td>\n",
       "      <td>15472</td>\n",
       "      <td>148372</td>\n",
       "      <td>2178-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2178-11-15**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>21</td>\n",
       "      <td>15472</td>\n",
       "      <td>188190</td>\n",
       "      <td>2178-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2178-12-5**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>22</td>\n",
       "      <td>15472</td>\n",
       "      <td>104146</td>\n",
       "      <td>2179-02-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2179-2-1**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>23</td>\n",
       "      <td>15472</td>\n",
       "      <td>143651</td>\n",
       "      <td>2179-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2179-3-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>24</td>\n",
       "      <td>15472</td>\n",
       "      <td>184486</td>\n",
       "      <td>2179-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2179-4-12**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROW_ID  SUBJECT_ID  HADM_ID   CHARTDATE  CHARTTIME  STORETIME  \\\n",
       "0      174       22532   167853  2151-08-04        NaN        NaN   \n",
       "1      175       13702   107527  2118-06-14        NaN        NaN   \n",
       "2      176       13702   167118  2119-05-25        NaN        NaN   \n",
       "3      177       13702   196489  2124-08-18        NaN        NaN   \n",
       "4      178       26880   135453  2162-03-25        NaN        NaN   \n",
       "..     ...         ...      ...         ...        ...        ...   \n",
       "95      20       15472   148372  2178-12-02        NaN        NaN   \n",
       "96      21       15472   188190  2178-12-09        NaN        NaN   \n",
       "97      22       15472   104146  2179-02-08        NaN        NaN   \n",
       "98      23       15472   143651  2179-03-26        NaN        NaN   \n",
       "99      24       15472   184486  2179-04-15        NaN        NaN   \n",
       "\n",
       "             CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0   Discharge summary      Report   NaN      NaN   \n",
       "1   Discharge summary      Report   NaN      NaN   \n",
       "2   Discharge summary      Report   NaN      NaN   \n",
       "3   Discharge summary      Report   NaN      NaN   \n",
       "4   Discharge summary      Report   NaN      NaN   \n",
       "..                ...         ...   ...      ...   \n",
       "95  Discharge summary      Report   NaN      NaN   \n",
       "96  Discharge summary      Report   NaN      NaN   \n",
       "97  Discharge summary      Report   NaN      NaN   \n",
       "98  Discharge summary      Report   NaN      NaN   \n",
       "99  Discharge summary      Report   NaN      NaN   \n",
       "\n",
       "                                                 TEXT  \n",
       "0   Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1   Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2   Admission Date:  [**2119-5-4**]              D...  \n",
       "3   Admission Date:  [**2124-7-21**]              ...  \n",
       "4   Admission Date:  [**2162-3-3**]              D...  \n",
       "..                                                ...  \n",
       "95  Admission Date:  [**2178-11-15**]             ...  \n",
       "96  Admission Date:  [**2178-12-5**]              ...  \n",
       "97  Admission Date:  [**2179-2-1**]              D...  \n",
       "98  Admission Date:  [**2179-3-21**]              ...  \n",
       "99  Admission Date:  [**2179-4-12**]              ...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
